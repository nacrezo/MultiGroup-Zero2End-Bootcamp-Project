{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Model: K-Means Clustering\n",
        "\n",
        "## Amaç\n",
        "\n",
        "En basit pipeline ve feature set ile temel bir kullanıcı segmentasyon modeli eğitmek. Bu, sonraki adımlarda iyileştirmelerimizi karşılaştıracağımız referans noktası olacak.\n",
        "\n",
        "### Baseline Stratejisi\n",
        "- **Model**: K-Means Clustering\n",
        "- **Feature Set**: En temel 4-5 özellik (engagement ve spending odaklı)\n",
        "- **Preprocessing**: Sadece StandardScaler\n",
        "- **Cluster Sayısı**: 4 (business rules'a göre)\n",
        "- **Metrikler**: Silhouette Score, Davies-Bouldin Index, Inertia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "import warnings\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(str(Path('..').resolve()))\n",
        "from src.config import *\n",
        "from src.data_loader import load_gaming_dataset, create_sample_gaming_dataset\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Veri Yükleme\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "try:\n",
        "    df = load_gaming_dataset(RAW_DATA_DIR)\n",
        "    if df is None or len(df) == 0:\n",
        "        raise FileNotFoundError(\"Dataset not found\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Creating sample dataset...\")\n",
        "    df = create_sample_gaming_dataset(n_samples=20000, save_path=TRAIN_FILE)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()[:10]}...\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Feature Set\n",
        "\n",
        "Baseline için en temel ve önemli özellikleri seçiyoruz:\n",
        "1. **SessionsPerWeek**: Toplam oturum sayısı (engagement)\n",
        "2. **PlayTimeHours**: Toplam oyun süresi (engagement)\n",
        "3. **InGamePurchases**: Toplam harcama (monetization)\n",
        "4. **login_frequency_per_week**: Haftalık giriş sıklığı (activity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline feature set - minimal features for segmentation\n",
        "baseline_features = [\n",
        "    'SessionsPerWeek',\n",
        "    'PlayTimeHours',\n",
        "    'InGamePurchases',\n",
        "    'SessionsPerWeek'\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "X_baseline = df[baseline_features].copy()\n",
        "\n",
        "# Handle missing values (if any)\n",
        "X_baseline = X_baseline.fillna(X_baseline.median())\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BASELINE FEATURE SET\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Features: {baseline_features}\")\n",
        "print(f\"\\nFeature Statistics:\")\n",
        "print(X_baseline.describe())\n",
        "print(f\"\\nMissing values: {X_baseline.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Veri Ön İşleme\n",
        "\n",
        "Clustering için veriyi standardize ediyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_baseline)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=baseline_features)\n",
        "\n",
        "print(\"Data standardized successfully!\")\n",
        "print(f\"Scaled data shape: {X_scaled_df.shape}\")\n",
        "print(f\"\\nScaled data statistics:\")\n",
        "print(X_scaled_df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimum Cluster Sayısını Belirleme (Elbow Method)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elbow method to find optimal number of clusters\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "print(\"Testing different numbers of clusters...\")\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, \n",
        "                    max_iter=300, random_state=MODEL_CONFIG['random_state'])\n",
        "    kmeans.fit(X_scaled)\n",
        "    \n",
        "    inertias.append(kmeans.inertia_)\n",
        "    sil_score = silhouette_score(X_scaled, kmeans.labels_)\n",
        "    silhouette_scores.append(sil_score)\n",
        "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={sil_score:.3f}\")\n",
        "\n",
        "# Plot results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Elbow curve\n",
        "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
        "axes[0].set_ylabel('Inertia', fontsize=12)\n",
        "axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Silhouette scores\n",
        "axes[1].plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
        "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
        "axes[1].set_title('Silhouette Score vs Number of Clusters', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find optimal k (highest silhouette score)\n",
        "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
        "print(f\"\\nOptimal number of clusters (based on silhouette): {optimal_k}\")\n",
        "print(f\"Best silhouette score: {max(silhouette_scores):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model: K-Means Clustering\n",
        "\n",
        "Business rules'a göre 4 cluster kullanıyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline model with 4 clusters (from business rules)\n",
        "n_clusters = BUSINESS_RULES['segment_count']\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING BASELINE MODEL\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Number of clusters: {n_clusters}\")\n",
        "print(f\"Features: {baseline_features}\")\n",
        "\n",
        "# Train K-Means\n",
        "kmeans_baseline = KMeans(\n",
        "    n_clusters=n_clusters,\n",
        "    init='k-means++',\n",
        "    n_init=10,\n",
        "    max_iter=300,\n",
        "    random_state=MODEL_CONFIG['random_state']\n",
        ")\n",
        "\n",
        "kmeans_baseline.fit(X_scaled)\n",
        "labels = kmeans_baseline.labels_\n",
        "\n",
        "# Add cluster labels to dataframe\n",
        "df_baseline = df.copy()\n",
        "df_baseline['cluster'] = labels\n",
        "\n",
        "print(f\"\\n✅ Model trained successfully!\")\n",
        "print(f\"Cluster distribution:\")\n",
        "print(df_baseline['cluster'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Değerlendirme Metrikleri\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate clustering metrics\n",
        "silhouette = silhouette_score(X_scaled, labels)\n",
        "davies_bouldin = davies_bouldin_score(X_scaled, labels)\n",
        "calinski_harabasz = calinski_harabasz_score(X_scaled, labels)\n",
        "inertia = kmeans_baseline.inertia_\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BASELINE MODEL METRICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
        "print(f\"  (Range: -1 to 1, higher is better)\")\n",
        "print(f\"  Interpretation: {'Good' if silhouette > 0.3 else 'Fair' if silhouette > 0.2 else 'Poor'}\")\n",
        "print()\n",
        "print(f\"Davies-Bouldin Index: {davies_bouldin:.4f}\")\n",
        "print(f\"  (Lower is better)\")\n",
        "print()\n",
        "print(f\"Calinski-Harabasz Index: {calinski_harabasz:.2f}\")\n",
        "print(f\"  (Higher is better)\")\n",
        "print()\n",
        "print(f\"Inertia (Within-cluster sum of squares): {inertia:.2f}\")\n",
        "print(f\"  (Lower is better)\")\n",
        "\n",
        "# Store baseline metrics\n",
        "baseline_metrics = {\n",
        "    'silhouette_score': silhouette,\n",
        "    'davies_bouldin_index': davies_bouldin,\n",
        "    'calinski_harabasz_index': calinski_harabasz,\n",
        "    'inertia': inertia,\n",
        "    'n_clusters': n_clusters,\n",
        "    'n_features': len(baseline_features)\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BASELINE METRICS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in baseline_metrics.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cluster Profilleme ve Analiz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cluster profiles\n",
        "print(\"=\" * 60)\n",
        "print(\"CLUSTER PROFILES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cluster_profile = df_baseline.groupby('cluster')[baseline_features].mean()\n",
        "cluster_profile['count'] = df_baseline.groupby('cluster').size()\n",
        "cluster_profile['percentage'] = (cluster_profile['count'] / len(df_baseline) * 100).round(2)\n",
        "\n",
        "print(\"\\nCluster Statistics (Mean values):\")\n",
        "print(cluster_profile)\n",
        "\n",
        "# Additional insights\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CLUSTER INSIGHTS\")\n",
        "print(\"=\" * 60)\n",
        "for cluster_id in range(n_clusters):\n",
        "    cluster_data = df_baseline[df_baseline['cluster'] == cluster_id]\n",
        "    print(f\"\\nCluster {cluster_id} ({len(cluster_data)} users, {len(cluster_data)/len(df_baseline)*100:.1f}%):\")\n",
        "    print(f\"  Avg Sessions: {cluster_data['SessionsPerWeek'].mean():.1f}\")\n",
        "    print(f\"  Avg Playtime: {cluster_data['PlayTimeHours'].mean():.1f} hours\")\n",
        "    print(f\"  Avg Spending: ${cluster_data['InGamePurchases'].mean():.2f}\")\n",
        "    print(f\"  Avg Login Frequency: {cluster_data['SessionsPerWeek'].mean():.2f} per week\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Görselleştirme: Cluster Dağılımları\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize clusters\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Playtime vs Spending\n",
        "scatter1 = axes[0, 0].scatter(df_baseline['PlayTimeHours'], \n",
        "                               df_baseline['InGamePurchases'],\n",
        "                               c=df_baseline['cluster'], \n",
        "                               cmap='viridis', \n",
        "                               alpha=0.6, \n",
        "                               s=30)\n",
        "axes[0, 0].set_xlabel('Total Playtime (Hours)', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Total Spent (USD)', fontsize=11)\n",
        "axes[0, 0].set_title('Clusters: Playtime vs Spending', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=axes[0, 0], label='Cluster')\n",
        "\n",
        "# Plot cluster centers\n",
        "centers = scaler.inverse_transform(kmeans_baseline.cluster_centers_)\n",
        "centers_df = pd.DataFrame(centers, columns=baseline_features)\n",
        "axes[0, 0].scatter(centers_df['PlayTimeHours'], \n",
        "                   centers_df['InGamePurchases'],\n",
        "                   c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# 2. Sessions vs Login Frequency\n",
        "scatter2 = axes[0, 1].scatter(df_baseline['SessionsPerWeek'], \n",
        "                               df_baseline['SessionsPerWeek'],\n",
        "                               c=df_baseline['cluster'], \n",
        "                               cmap='plasma', \n",
        "                               alpha=0.6, \n",
        "                               s=30)\n",
        "axes[0, 1].set_xlabel('Total Sessions', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Login Frequency per Week', fontsize=11)\n",
        "axes[0, 1].set_title('Clusters: Sessions vs Login Frequency', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter2, ax=axes[0, 1], label='Cluster')\n",
        "axes[0, 1].scatter(centers_df['SessionsPerWeek'], \n",
        "                   centers_df['SessionsPerWeek'],\n",
        "                   c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# 3. Cluster size distribution\n",
        "cluster_counts = df_baseline['cluster'].value_counts().sort_index()\n",
        "axes[1, 0].bar(cluster_counts.index.astype(str), cluster_counts.values, \n",
        "               color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
        "axes[1, 0].set_xlabel('Cluster', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Number of Users', fontsize=11)\n",
        "axes[1, 0].set_title('Cluster Size Distribution', fontsize=12, fontweight='bold')\n",
        "for i, v in enumerate(cluster_counts.values):\n",
        "    axes[1, 0].text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Feature means by cluster\n",
        "cluster_means = df_baseline.groupby('cluster')[baseline_features].mean()\n",
        "x = np.arange(len(baseline_features))\n",
        "width = 0.2\n",
        "for i, cluster_id in enumerate(range(n_clusters)):\n",
        "    offset = (i - n_clusters/2 + 0.5) * width\n",
        "    axes[1, 1].bar(x + offset, cluster_means.loc[cluster_id], \n",
        "                   width, label=f'Cluster {cluster_id}', alpha=0.8)\n",
        "axes[1, 1].set_xlabel('Features', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Mean Value', fontsize=11)\n",
        "axes[1, 1].set_title('Feature Means by Cluster', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xticks(x)\n",
        "axes[1, 1].set_xticklabels(baseline_features, rotation=45, ha='right')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Sonuçları ve Özet\n",
        "\n",
        "### Baseline Model Özeti\n",
        "\n",
        "**Model**: K-Means Clustering\n",
        "- **Cluster Sayısı**: 4\n",
        "- **Feature Sayısı**: 4 (minimal set)\n",
        "- **Features**: SessionsPerWeek, PlayTimeHours, InGamePurchases, login_frequency_per_week\n",
        "- **Preprocessing**: StandardScaler\n",
        "\n",
        "### Baseline Metrikleri\n",
        "\n",
        "- **Silhouette Score**: {baseline_metrics['silhouette_score']:.4f}\n",
        "- **Davies-Bouldin Index**: {baseline_metrics['davies_bouldin_index']:.4f}\n",
        "- **Calinski-Harabasz Index**: {baseline_metrics['calinski_harabasz_index']:.2f}\n",
        "- **Inertia**: {baseline_metrics['inertia']:.2f}\n",
        "\n",
        "### Sonraki Adımlar\n",
        "\n",
        "1. **Feature Engineering**: Daha fazla özellik ekleyerek model performansını artırma\n",
        "2. **Feature Selection**: En önemli özellikleri seçme\n",
        "3. **Model Optimization**: Farklı clustering algoritmaları deneme\n",
        "4. **Hyperparameter Tuning**: Cluster sayısı ve diğer parametreleri optimize etme\n",
        "\n",
        "### Notlar\n",
        "\n",
        "- Baseline model basit bir başlangıç noktasıdır\n",
        "- Silhouette score'un 0.3'ün üzerinde olması iyi bir başlangıç\n",
        "- Feature engineering ile daha iyi segmentasyon bekleniyor\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}